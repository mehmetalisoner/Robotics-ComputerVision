{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we're going to demonstrate using one of the ready-to-download, open-access datasets from TorchVision, how to transform the images for consumption by your model, and how to use the DataLoader to feed batches of data to your model.\n",
    "\n",
    "The first thing we need to do is transform our incoming images into a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we specify two transformations for our input:\n",
    "* `transforms.ToTensor()` converts images loaded by Pillow into PyTorch tensors.\n",
    "* `transforms.Normalize()` adjusts the values of the tensor so that their average is zero and their standard deviation is 0.5. Most activation functions have their strongest gradients around x = 0, so centering our data there can speed learning.\n",
    "\n",
    "There are many more transforms available, including cropping, centering, rotation, and reflection.\n",
    "\n",
    "Next, we'll create an instance of the CIFAR10 dataset. This is a set of 32x32 color image tiles representing 10 classes of objects: 6 of animals (bird, cat, deer, dog, frog, horse) and 4 of vehicles (airplane, automobile, ship, truck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: When you run the cell above, it may take a little time for the dataset to download.*\n",
    "\n",
    "This is an example of creating a dataset object in PyTorch. Downloadable datasets (like CIFAR-10 above) are subclasses of `torch.utils.data.Dataset`. `Dataset` classes in PyTorch include the downloadable datasets in TorchVision, Torchtext, and TorchAudio, as well as utility dataset classes such as `torchvision.datasets.ImageFolder`, which will read a folder of labeled images. You can also create your own subclasses of `Dataset`.\n",
    "\n",
    "When we instantiate our dataset, we need to tell it a few things:\n",
    "* The filesystem path to where we want the data to go\n",
    "* Whether or not we are using this set for training; most datasets will be split into training and test subsets.\n",
    "* Whether we would like to download the dataset if we haven't already\n",
    "* The transformations we want to apply to the data\n",
    "\n",
    "Once your dataset is ready, you can give it to the `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` subclass wraps access to the data, and is specialized to the type of data it's serving. The `DataLoader` knows *nothing* about the data, but organizes the input tensors served by the `Dataset` into batches with the parameters you specify.\n",
    "\n",
    "In the example above, we've asked a `DataLoader` to give us batches of 4 images from `trainset`, randomizing their order (`shuffle=True`), and we told it to spin up two workers to load data from disk.\n",
    "\n",
    "It's good practice to visualize the batches your `DataLoader` serves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# get some random training images\u001b[39;00m\n\u001b[0;32m     14\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(trainloader)\n\u001b[1;32m---> 15\u001b[0m images, labels \u001b[39m=\u001b[39m dataiter\u001b[39m.\u001b[39;49mnext()\n\u001b[0;32m     17\u001b[0m \u001b[39m# show images\u001b[39;00m\n\u001b[0;32m     18\u001b[0m imshow(torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images))\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above cell should show you a strip of four images, and the correct label for each."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "101498bf91cd08ed38643c0d863d6cf15c6060df1343914c817ebac5a997e30a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
